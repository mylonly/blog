<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>  
	  
  	利用Scrapy-Splash抓取JS动态渲染的网页数据 - 独自一人
  	
	</title>

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

	<link href="atom.xml" rel="alternate" title="独自一人" type="application/atom+xml">

	<link href="asset/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="asset/stylesheets/font-awesome.min.css" media="screen, projection" rel="stylesheet" type="text/css">
	<script src="asset/javascripts/jquery.min.js"></script>
	<script src="asset/highlightjs/highlight.pack.js"></script>
	<link href="asset/highlightjs/styles/solarized_dark.css" media="screen, projection" rel="stylesheet" type="text/css">
<script>hljs.initHighlightingOnLoad();</script>

	<!--[if lt IE 9]><script src="asset/javascripts/html5.js"></script><![endif]-->
	<!-- <link href='http://fonts.googleapis.com/css?family=Nunito:400,300,700' rel='stylesheet' type='text/css'> -->
	<style type="text/css">
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 300;
  src: local('Nunito-Light'), url(asset/font/1TiHc9yag0wq3lDO9cw0voX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 400;
  src: local('Nunito-Regular'), url(asset/font/6TbRXKWJjpj6V2v_WyRbMX-_kf6ByYO6CLYdB4HQE-Y.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 700;
  src: local('Nunito-Bold'), url(asset/font/TttUCfJ272GBgSKaOaD7KoX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
	</style>
	
	<style type="text/css">
	.container .left-col{ opacity: 1;}
	#pagenavi a{ font-size: 1.3em;}
	#pagenavi .next:before{ top: 3px;}
	#pagenavi .prev:before{ top: 3px;}
	.container .mid-col .mid-col-container #content .archives .title{ font-size: 1.5em;}
	.container .mid-col .mid-col-container #content article{ padding: 15px 0px;}
	#header .subtitle {
		line-height: 1.2em;
		padding-top: 8px;
	}
	article pre{ background: none; border: none; padding: 0;}
	article .entry-content{text-align: left;}
	.share-comment{ padding: 25px 0px; clear: both;}
	hr{ margin: 20px 0px;border: 0; border-top:solid 1px #ddd;}
	</style>
  

</head>


<body>
	<div class="container">
		<div class="left-col">
			<div class="intrude-less">
				<header id="header" class="inner">
				 
				 	<div class="profilepic">
						<img src="https://pic.mylonly.com/2017-05-11-IMG_1164.JPG" style="width:160px;">
					</div>
            	
					
					<h1><a href="index.html">独自一人</a></h1>
					<p class="subtitle">独自一人,独自Coding...</p>
					<nav id="main-nav">
						<ul class="main">
						
						  <li id=""><a target="self" href="index.html">Home</a></li>
						
						  <li id=""><a target="_self" href="archives.html">Archives</a></li>
						
						</ul>
					</nav>

					<nav id="sub-nav">
						<div class="social">










<a target="_blank" class="github" target="_blank" href="https://github.com/mylonly" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:root@mylonly.com" title="Email">Email</a>

								

								<a class="rss" href="atom.xml" title="RSS">RSS</a>
							
						</div>
					</nav>
				</header>				
			</div>
		</div>	
		<div class="mid-col">
			<div class="mid-col-container"> <div id="content" class="inner">

	<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
		<h1 class="title" itemprop="name">利用Scrapy-Splash抓取JS动态渲染的网页数据</h1>
		<div class="entry-content" itemprop="articleBody">
			<p>随着越来越多的网站开始用JS在客户端浏览器动态渲染网站，导致很多我们需要的数据并不能由原始的html中获取，再加上Scrapy本身并不提供JS渲染解析的功能，通常对这类网站数据的爬取我们一般采用两种方法：</p>

<ol>
<li>通过分析网站，找到对应数据的接口，模拟接口去获取我们需要的数据(参见<a href="https://www.mylonly.com/14945011244738.html">Scrapy抓取Ajax动态页面</a>),但是一旦该网站的接口隐藏的很深，或者接口的加密过于复杂，此种方法可能就有点行不通了</li>
<li>借助JS内核，将获取到的含有JS脚本的页面交由JS内核去渲染，最后将渲染后生成的html返回给Scrapy分析，比较常见的WebKit和Scrapy-Splash</li>
</ol>

<p>本篇文章的目的就是用来介绍如何使用Scrapy-Splash来配合Scrapy抓取动态页面这个问题。</p>

<h3 id="toc_0">准备工作</h3>

<ol>
<li><p>Docker安装,具体安装步骤参考<a href="https://docs.docker.com/engine/installation/">Docker官网</a></p>

<blockquote>
<p>为什么要安装Docker?<br/>
因为Scrapy-Splash使用了<code>Splash HTTP API</code>,所以你需要提供一个Splash实例，而在Docker镜像中已经有现成的Splash实例了，可以很方便的使用。</p>
</blockquote></li>
<li><p>Docker镜像源更改,参考<a href="https://ieevee.com/tech/2016/09/28/docker-mirror.html">国内 docker 仓库镜像对比</a></p></li>
<li><p>安装运行Splash</p>

<pre><code>docker pull scrapinghub/splash   #从docker镜像中拉取splash实例
docker run -p 8050:8050 scrapinghub/splash  #启动splash实例
</code></pre></li>
</ol>

<h3 id="toc_1">Scrapy配置</h3>

<p>在Scrapy项目的setting.py中加入如下内容：</p>

<pre><code class="language-Python">SPLASH_URL = &#39;http://localhost:8050&#39;  

DOWNLOADER_MIDDLEWARES = {
&#39;scrapy_splash.SplashCookiesMiddleware&#39;: 723,
&#39;scrapy_splash.SplashMiddleware&#39;: 725,
&#39;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#39;: 810,
}

SPIDER_MIDDLEWARES = {
&#39;scrapy_splash.SplashDeduplicateArgsMiddleware&#39;: 100,
}

DUPEFILTER_CLASS = &#39;scrapy_splash.SplashAwareDupeFilter&#39;

HTTPCACHE_STORAGE = &#39;scrapy_splash.SplashAwareFSCacheStorage&#39;

</code></pre>

<h3 id="toc_2">实际代码解析</h3>

<p>我们以<a href="http://stock.qq.com/l/stock/ywq/list20150423143546.htm">腾讯证券</a>这个页面为例，腾讯的证券新闻列表是js动态渲染而成</p>

<p>我们直接打开这个链接，然后打开开发者工具，定位到新闻列表处:<br/>
<img src="https://pic.mylonly.com/2017-09-12-074653.jpg" alt=""/></p>

<p>我们在从network中查看第一次请求的Response时发现，返回的html中该列表页处是空的<br/><br/>
<img src="https://pic.mylonly.com/2017-09-12-075028.jpg" alt=""/></p>

<p>实际的数据被藏着JS里，加载完成后由JS操作DOM插入完成<br/>
<img src="https://pic.mylonly.com/2017-09-12-075305.jpg" alt=""/></p>

<p>此处由于实际数据被塞到了一段JS的变量里面，并不是由Ajax调用接口获取的，因此为了避免自己手动去截取js变量，我们便将该页面交给Scrapy-Splash渲染</p>

<pre><code class="language-Python">import scrapy
from FinancialInfoSpider.items import ArticleItem
from scrapy_splash import SplashRequest
from w3lib.html import remove_tags
import re
from bs4 import BeautifulSoup

class TencentStockSpider(scrapy.Spider):
    name = &quot;TencentStock&quot;
    def start_requests(self):
        urls = [
           &#39;http://stock.qq.com/l/stock/ywq/list20150423143546.htm&#39;,
        ]

        for url in urls:
            yield SplashRequest(url, self.parse, args={&#39;wait&#39;: 0.5})

    def parse(self,response):

        sel = scrapy.Selector(response)
        links = sel.xpath(&quot;//div[@class=&#39;qq_main&#39;]//ul[@class=&#39;listInfo&#39;]//li//div[@class=&#39;info&#39;]//h3//a/@href&quot;).extract()
        requests = []
        
        for link in links:
            request = scrapy.Request(link, callback =self.parse_article)
            requests.append(request)
        return requests

    def parse_article(self,response):

        sel = scrapy.Selector(response)

        article = ArticleItem()
        article[&#39;title&#39;] = sel.xpath(&#39;//*[@id=&quot;Main-Article-QQ&quot;]/div/div[1]/div[1]/div[1]/h1/text()&#39;).extract()[0]
        article[&#39;source&#39;] = sel.xpath(&#39;//*[@id=&quot;Main-Article-QQ&quot;]/div/div[1]/div[1]/div[1]/div/div[1]/span[2]&#39;).xpath(&#39;string(.)&#39;).extract()[0]
        article[&#39;pub_time&#39;] = sel.xpath(&#39;//*[@id=&quot;Main-Article-QQ&quot;]/div/div[1]/div[1]/div[1]/div/div[1]/span[3]/text()&#39;).extract()[0]
        
        html_content = sel.xpath(&#39;//*[@id=&quot;Cnt-Main-Article-QQ&quot;]&#39;).extract()[0]
        article[&#39;content&#39;] = self.remove_html_tags(html_content)
        return article


    def remove_html_tags(self,html):
        
        soup = BeautifulSoup(html)
        [s.extract() for s in soup(&#39;script&#39;)]
        [s.extract() for s in soup(&#39;style&#39;)] 
         
        content = &#39;&#39;
        for substring in soup.stripped_strings:
            content = content + substring

        return content       
</code></pre>

<p>主要代码就一句，将获取到的页面发送给本地的Splash实例去渲染解析，最后将结果返回给parse函数解析</p>

<pre><code>SplashRequest(url, self.parse, args={&#39;wait&#39;: 0.5})
</code></pre>

<p>里面用了BeautifulSoup这个库去除了html中得script和style标签，具体用法可以参考这两篇文章:</p>

<p><a href="http://cuiqingcai.com/1319.html">Python爬虫利器二之Beautiful Soup的用法</a><br/>
<a href="https://my.oschina.net/letiantian/blog/504669">使用BeautifulSoup删除html中的script、注释</a></p>

<p>输出结果:</p>

<p><img src="https://pic.mylonly.com/2017-09-12-080930.jpg" alt=""/></p>

		</div>
	</article>
	<div class="share-comment">
	 

	  

	  

	</div>
</div>        </div>
			<footer id="footer" class="inner">Copyright &copy; 2014
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; 
Theme by <a href="http://shashankmehta.in/archive/2012/greyshade.html">Shashank Mehta</a>
      </footer>
		</div>
	</div>

  
    



</body>
</html>